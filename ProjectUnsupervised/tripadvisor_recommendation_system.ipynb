{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TripAdvisor Recommendation System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/alexs/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/alexs/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame shape: (878561, 10)\n",
      "DataFrame shape after filtering: (436391, 10)\n",
      "   offering_id   service  cleanliness   overall     value  location  \\\n",
      "0        72572  4.601010     4.636364  4.388889  4.323232  4.570707   \n",
      "1        72579  4.232000     4.240000  3.888000  4.152000  4.192000   \n",
      "2        72586  4.250000     4.287879  4.045455  4.053030  4.537879   \n",
      "3        72598  3.243243     3.243243  2.918919  3.054054  3.027027   \n",
      "4        73236  4.277778     3.111111  3.388889  3.777778  4.111111   \n",
      "\n",
      "   sleep_quality     rooms                                            reviews  \n",
      "0       4.333333  4.282828  I had to make fast visit to seattle and I foun...  \n",
      "1       3.768000  3.856000  Great service, rooms were clean, could use som...  \n",
      "2       4.113636  3.992424  Beautiful views of the space needle - especial...  \n",
      "3       3.270270  3.189189  This hotel is in need of some serious updates....  \n",
      "4       3.722222  3.222222  My experience at this days inn was perfect. th...  \n",
      "\n",
      "DataFrame shape: (3754, 9)\n",
      "\n",
      "Column names: ['offering_id', 'service', 'cleanliness', 'overall', 'value', 'location', 'sleep_quality', 'rooms', 'reviews']\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('reviews.csv')\n",
    "\n",
    "print(f\"Original DataFrame shape: {df.shape}\")\n",
    "\n",
    "# Convert the 'ratings' column from string to dictionary\n",
    "df['ratings'] = df['ratings'].apply(ast.literal_eval)\n",
    "\n",
    "# Define required aspects\n",
    "required_aspects = [\"service\", \"cleanliness\", \"overall\", \"value\", \"location\", \"sleep_quality\", \"rooms\"]\n",
    "\n",
    "# Filter rows with at least the required aspects\n",
    "df_filtered = df[df['ratings'].apply(lambda x: all(aspect in x for aspect in required_aspects))]\n",
    "\n",
    "print(f\"DataFrame shape after filtering: {df_filtered.shape}\")\n",
    "\n",
    "if df_filtered.empty:\n",
    "    print(\"No reviews found with all required aspects. Printing unique aspects found in the dataset:\")\n",
    "    all_aspects = set()\n",
    "    for rating in df['ratings']:\n",
    "        all_aspects.update(rating.keys())\n",
    "    print(sorted(all_aspects))\n",
    "    data = pd.DataFrame(columns=['offering_id'] + required_aspects + ['reviews'])\n",
    "else:\n",
    "    # Group by offering_id\n",
    "    data = df_filtered.groupby('offering_id').agg({\n",
    "        'text': ' '.join,  # Concatenate all reviews\n",
    "        'ratings': list  # Keep all ratings\n",
    "    }).reset_index()\n",
    "\n",
    "    # Calculate average ratings for each aspect\n",
    "    for aspect in required_aspects:\n",
    "        data[aspect] = data['ratings'].apply(lambda x: np.mean([review.get(aspect, np.nan) for review in x]))\n",
    "\n",
    "    # Rename 'text' column to 'reviews'\n",
    "    data = data.rename(columns={'text': 'reviews'})\n",
    "\n",
    "    # Select and order the final columns\n",
    "    final_columns = ['offering_id'] + required_aspects + ['reviews']\n",
    "    data = data[final_columns]\n",
    "\n",
    "# Print the first few rows and shape of the processed data\n",
    "print(data.head())\n",
    "print(\"\\nDataFrame shape:\", data.shape)\n",
    "\n",
    "# Print column names to verify\n",
    "print(\"\\nColumn names:\", data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Text Preprocessing\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords and punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words and token not in string.punctuation]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply text preprocessing to reviews\n",
    "data['processed_review'] = data['reviews'].apply(preprocess_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Definition and eval function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_bm25_model(corpus):\n",
    "    try:\n",
    "        tokenized_corpus = [doc.split() for doc in corpus if isinstance(doc, str)]\n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "        return bm25\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating BM25 model: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hybrid_model_with_dense_retriever(corpus, alpha=0.85, beta=0.15):\n",
    "    \"\"\"\n",
    "    Creates a hybrid model combining BM25 and SentenceTransformer (all-mpnet-base-v2)\n",
    "    with proper tensor handling for Apple Silicon\n",
    "    \"\"\"\n",
    "    # Initialize models\n",
    "    tokenized_corpus = [doc.split() for doc in corpus if isinstance(doc, str)]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    dense_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    \n",
    "    # Pre-compute document embeddings and move to CPU\n",
    "    doc_embeddings = dense_model.encode(corpus, convert_to_tensor=True)\n",
    "    doc_embeddings = doc_embeddings.cpu()  # Move to CPU\n",
    "    \n",
    "    def get_hybrid_scores(query_text):\n",
    "        try:\n",
    "            # 1. Get BM25 scores\n",
    "            query_tokens = query_text.split()\n",
    "            bm25_scores = np.array(bm25.get_scores(query_tokens))\n",
    "                    \n",
    "            # 2. Get dense retriever scores\n",
    "            query_embedding = dense_model.encode(query_text, convert_to_tensor=True)\n",
    "            query_embedding = query_embedding.cpu()  # Move to CPU\n",
    "            \n",
    "            # Reshape embeddings for cosine similarity\n",
    "            query_embedding_reshaped = query_embedding.reshape(1, -1)\n",
    "            doc_embeddings_reshaped = doc_embeddings.reshape(len(corpus), -1)\n",
    "            \n",
    "            # Calculate cosine similarity\n",
    "            dense_scores = cosine_similarity(query_embedding_reshaped, doc_embeddings_reshaped)[0]\n",
    "              \n",
    "            # Combine scores\n",
    "            final_scores = alpha * bm25_scores + beta * dense_scores\n",
    "            \n",
    "            return final_scores\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in hybrid scoring: {e}\")\n",
    "            return np.zeros(len(corpus))\n",
    "    \n",
    "    return get_hybrid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, query_data, full_data, model_type='hybrid', k=5):\n",
    "    \"\"\"\n",
    "    Improved evaluation function for recommendation models\n",
    "    Args:\n",
    "        model: The model to evaluate (BM25 or hybrid)\n",
    "        query_data: DataFrame containing query samples\n",
    "        full_data: Complete DataFrame with all hotels\n",
    "        model_type: 'bm25' or 'hybrid'\n",
    "        k: Number of similar hotels to consider\n",
    "    Returns:\n",
    "        float: Average MSE across all queries\n",
    "    \"\"\"\n",
    "    mse_scores = []\n",
    "    aspects = [\"service\", \"cleanliness\", \"overall\", \"value\", \"location\", \"sleep_quality\", \"rooms\"]\n",
    "    \n",
    "    for idx, query in query_data.iterrows():\n",
    "        try:\n",
    "            # Get similarity scores based on model type\n",
    "            if model_type == 'bm25':\n",
    "                tokenized_query = query['processed_review'].split()\n",
    "                scores = model.get_scores(tokenized_query)\n",
    "            else:  # hybrid model\n",
    "                scores = model(query['processed_review'])\n",
    "            \n",
    "            # Create mask to exclude the query hotel itself\n",
    "            mask = np.ones(len(scores), dtype=bool)\n",
    "            query_hotel_id = query['offering_id']\n",
    "            mask[full_data['offering_id'] == query_hotel_id] = False\n",
    "            \n",
    "            # Apply mask and get top-k indices\n",
    "            masked_scores = scores[mask]\n",
    "            masked_indices = np.argsort(masked_scores)[-k:]\n",
    "            \n",
    "            # Map masked indices back to original indices\n",
    "            top_k_idx = np.where(mask)[0][masked_indices]\n",
    "            \n",
    "            # Calculate ratings\n",
    "            similar_ratings = []\n",
    "            query_ratings = []\n",
    "            \n",
    "            for aspect in aspects:\n",
    "                # Get average rating for similar hotels\n",
    "                avg_rating = full_data.iloc[top_k_idx][aspect].mean()\n",
    "                similar_ratings.append(avg_rating)\n",
    "                query_ratings.append(query[aspect])\n",
    "            \n",
    "            # Calculate MSE\n",
    "            mse = mean_squared_error(query_ratings, similar_ratings)\n",
    "            mse_scores.append(mse)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing query {idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Return average MSE\n",
    "    if not mse_scores:\n",
    "        print(\"Warning: No valid evaluations were performed\")\n",
    "        return float('inf')\n",
    "    \n",
    "    avg_mse = np.mean(mse_scores)\n",
    "    std_mse = np.std(mse_scores)\n",
    "    print(f\"Number of evaluated queries: {len(mse_scores)}\")\n",
    "    print(f\"MSE Average for {model_type} model: {avg_mse:.4f}\")\n",
    "    print(f\"MSE Standard Deviation for {model_type} model: {std_mse:.4f}\")\n",
    "    \n",
    "    return avg_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of data for querying (e.g., 100 random samples)\n",
    "query_data = data.sample(n=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of evaluated queries: 100\n",
      "MSE Average for bm25 model: 0.4885\n",
      "MSE Standard Deviation for bm25 model: 0.8819\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create models using the full dataset\n",
    "bm25_model_full = create_bm25_model(data['processed_review'])\n",
    "\n",
    "bm25_score = evaluate_model(bm25_model_full, query_data, data, 'bm25')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of evaluated queries: 100\n",
      "MSE Average for hybrid model: 0.4891\n",
      "MSE Standard Deviation for hybrid model: 0.8818\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "# Create and evaluate the hybrid model\n",
    "hybrid_model = create_hybrid_model_with_dense_retriever(\n",
    "    corpus=data['processed_review'],\n",
    "    alpha=0.75,  # Weight for BM25\n",
    "    beta=0.25    # Weight for dense retriever\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "hybrid_score = evaluate_model(hybrid_model, query_data, data, 'hybrid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
